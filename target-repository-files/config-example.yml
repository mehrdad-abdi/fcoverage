# This is a sample configuration file for the target repository.

feature-file: .fcoverage/feature-list.md
vector-db-persist-location: .fcoverage/vdb
report-file: .fcoverage/report.md
prompts-directory: .fcoverage/prompts


documents:
    - README.md
    # - docs/file1.md
    # - examples/file2.md
    # - changes_log.md

tests: tests
source: src

llm:
    # List of supported LLM models: https://python.langchain.com/docs/integrations/chat/
    model: gemini-2.0-flash # gemini-2.0-flash, gpt-4, gpt-4o-mini, claude-3-5-sonnet-latest
    provider: google_genai  # anthropic, openai, google_genai
    # Don't forget to set the environment variable like `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`

embedding:
    model: models/gemini-embedding-exp-03-07
    provider: google_genai  # "offline" or use online models like openai, google_genai, anthropic
    # If online, don't forget to set the environment variable like `OPENAI_API_KEY` or `GOOGLE_API_KEY`
    batch-size: 32
